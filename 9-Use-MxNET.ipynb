{"cells":[{"cell_type":"markdown","source":["To install MXNet on a single node using the following script (for the community edition because the driver and the worker are on the same node).  \n* Run the script below.\n\n**NOTE: Use an init script to install on a multi-node cluster. Using this script on a multinode cluster will not work, because MXNet will only be installed on the driver.  The init script solves this problem by running the install script when the worker launches. **"],"metadata":{}},{"cell_type":"code","source":["%sh\n\nrm -rf /usr/local/mxnet\n\nmxnetGitTag=\"eaa6253\"\n\nset -ex\n\necho \"**** Installing MXNet dependencies ****\"\n\napt-get update\n\n# Requirements stated in http://mxnet.io/get_started/setup.html#standard-installation.\n# We used OpenBLAS instead of ATLAS.\napt-get install -y build-essential git libopenblas-dev libopencv-dev python-numpy python-setuptools\n\necho \"**** Downloading MXNet ****\"\n\nMXNET_HOME=/usr/local/mxnet\ngit clone --recursive https://github.com/dmlc/mxnet $MXNET_HOME\ncd $MXNET_HOME\ngit checkout ${mxnetGitTag}\ngit submodule update\n\necho \"**** Building MXNet ****\"\n\nUSE_CUDA=0 USE_CUDNN=0 USE_CUDA_PATH=/usr/local/cuda USE_BLAS=openblas make -e -j$(nproc)\n\necho \"**** Installing MXNet ****\"\n\ncd python\npython setup.py install"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+ echo &#39;**** Installing MXNet dependencies ****&#39;\n**** Installing MXNet dependencies ****\n+ apt-get update\nHit:1 http://security.ubuntu.com/ubuntu xenial-security InRelease\nHit:2 http://archive.ubuntu.com/ubuntu xenial InRelease\nHit:3 http://archive.ubuntu.com/ubuntu xenial-updates InRelease\nHit:4 http://archive.ubuntu.com/ubuntu xenial-backports InRelease\nReading package lists...\n+ apt-get install -y build-essential git libopenblas-dev libopencv-dev python-numpy python-setuptools\nReading package lists...\nBuilding dependency tree...\nReading state information...\nbuild-essential is already the newest version (12.1ubuntu2).\npython-numpy is already the newest version (1:1.11.0-1ubuntu1).\npython-setuptools is already the newest version (20.7.0-1).\nlibopenblas-dev is already the newest version (0.2.18-1ubuntu1).\ngit is already the newest version (1:2.7.4-0ubuntu1.7).\nlibopencv-dev is already the newest version (2.4.9.1+dfsg-1.5ubuntu1.1).\nThe following package was automatically installed and is no longer required:\n  libgnutls-openssl27\nUse &#39;sudo apt autoremove&#39; to remove it.\n0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n+ echo &#39;**** Downloading MXNet ****&#39;\n**** Downloading MXNet ****\n+ MXNET_HOME=/usr/local/mxnet\n+ git clone --recursive https://github.com/dmlc/mxnet /usr/local/mxnet\nCloning into &#39;/usr/local/mxnet&#39;...\nSubmodule &#39;3rdparty/dlpack&#39; (https://github.com/dmlc/dlpack) registered for path &#39;3rdparty/dlpack&#39;\nSubmodule &#39;3rdparty/dmlc-core&#39; (https://github.com/dmlc/dmlc-core.git) registered for path &#39;3rdparty/dmlc-core&#39;\nSubmodule &#39;3rdparty/googletest&#39; (https://github.com/google/googletest.git) registered for path &#39;3rdparty/googletest&#39;\nSubmodule &#39;3rdparty/mkldnn&#39; (https://github.com/intel/mkl-dnn.git) registered for path &#39;3rdparty/mkldnn&#39;\nSubmodule &#39;3rdparty/nvidia_cub&#39; (https://github.com/NVlabs/cub.git) registered for path &#39;3rdparty/nvidia_cub&#39;\nSubmodule &#39;3rdparty/onnx-tensorrt&#39; (https://github.com/onnx/onnx-tensorrt.git) registered for path &#39;3rdparty/onnx-tensorrt&#39;\nSubmodule &#39;3rdparty/openmp&#39; (https://github.com/llvm-mirror/openmp) registered for path &#39;3rdparty/openmp&#39;\nSubmodule &#39;3rdparty/ps-lite&#39; (https://github.com/dmlc/ps-lite) registered for path &#39;3rdparty/ps-lite&#39;\nSubmodule &#39;3rdparty/tvm&#39; (https://github.com/apache/incubator-tvm.git) registered for path &#39;3rdparty/tvm&#39;\nCloning into &#39;3rdparty/dlpack&#39;...\nSubmodule path &#39;3rdparty/dlpack&#39;: checked out &#39;b90e939072066c160b18ea1e7156537b8d3710f6&#39;\nCloning into &#39;3rdparty/dmlc-core&#39;...\nSubmodule path &#39;3rdparty/dmlc-core&#39;: checked out &#39;b3a4c715bfc37a08f245844a800933f10e47c1ea&#39;\nCloning into &#39;3rdparty/googletest&#39;...\nSubmodule path &#39;3rdparty/googletest&#39;: checked out &#39;eb9225ce361affe561592e0912320b9db84985d0&#39;\nCloning into &#39;3rdparty/mkldnn&#39;...\nSubmodule path &#39;3rdparty/mkldnn&#39;: checked out &#39;cb2cc7ac17ff4e2ef50805c7048d33256d82be4d&#39;\nCloning into &#39;3rdparty/nvidia_cub&#39;...\nSubmodule path &#39;3rdparty/nvidia_cub&#39;: checked out &#39;c3cceac115c072fb63df1836ff46d8c60d9eb304&#39;\nCloning into &#39;3rdparty/onnx-tensorrt&#39;...\nSubmodule path &#39;3rdparty/onnx-tensorrt&#39;: checked out &#39;f4745fcaff868a519834917c657f105a8eef2f53&#39;\nSubmodule &#39;third_party/onnx&#39; (https://github.com/onnx/onnx.git) registered for path &#39;third_party/onnx&#39;\nCloning into &#39;third_party/onnx&#39;...\nSubmodule path &#39;3rdparty/onnx-tensorrt/third_party/onnx&#39;: checked out &#39;765f5ee823a67a866f4bd28a9860e81f3c811ce8&#39;\nSubmodule &#39;third_party/benchmark&#39; (https://github.com/google/benchmark.git) registered for path &#39;third_party/benchmark&#39;\nSubmodule &#39;third_party/pybind11&#39; (https://github.com/pybind/pybind11.git) registered for path &#39;third_party/pybind11&#39;\nCloning into &#39;third_party/benchmark&#39;...\nSubmodule path &#39;3rdparty/onnx-tensorrt/third_party/onnx/third_party/benchmark&#39;: checked out &#39;e776aa0275e293707b6a0901e0e8d8a8a3679508&#39;\nCloning into &#39;third_party/pybind11&#39;...\nSubmodule path &#39;3rdparty/onnx-tensorrt/third_party/onnx/third_party/pybind11&#39;: checked out &#39;a1041190c8b8ff0cd9e2f0752248ad5e3789ea0c&#39;\nSubmodule &#39;tools/clang&#39; (https://github.com/wjakob/clang-cindex-python3) registered for path &#39;tools/clang&#39;\nCloning into &#39;tools/clang&#39;...\nSubmodule path &#39;3rdparty/onnx-tensorrt/third_party/onnx/third_party/pybind11/tools/clang&#39;: checked out &#39;6a00cbc4a9b8e68b71caf7f774b3f9c753ae84d5&#39;\nCloning into &#39;3rdparty/openmp&#39;...\nSubmodule path &#39;3rdparty/openmp&#39;: checked out &#39;b76842ed16984ae5edcbbc4b00a94fda20419431&#39;\nCloning into &#39;3rdparty/ps-lite&#39;...\nSubmodule path &#39;3rdparty/ps-lite&#39;: checked out &#39;60b826e4422fee0df00b892c66ffffea11e5da3f&#39;\nCloning into &#39;3rdparty/tvm&#39;...\nSubmodule path &#39;3rdparty/tvm&#39;: checked out &#39;5d66e7a695d1d40e08cf2da802b5e2b7015b758a&#39;\nSubmodule &#39;dlpack&#39; (https://github.com/dmlc/dlpack) registered for path &#39;3rdparty/dlpack&#39;\nSubmodule &#39;dmlc-core&#39; (https://github.com/dmlc/dmlc-core) registered for path &#39;3rdparty/dmlc-core&#39;\nSubmodule &#39;3rdparty/rang&#39; (https://github.com/agauniyal/rang) registered for path &#39;3rdparty/rang&#39;\nCloning into &#39;3rdparty/dlpack&#39;...\nSubmodule path &#39;3rdparty/tvm/3rdparty/dlpack&#39;: checked out &#39;0acb731e0e43d15deee27b66f10e4c5b4e667913&#39;\nCloning into &#39;3rdparty/dmlc-core&#39;...\nSubmodule path &#39;3rdparty/tvm/3rdparty/dmlc-core&#39;: checked out &#39;808f485387f9a03f78fa9f1159f387d0d91b7a28&#39;\nCloning into &#39;3rdparty/rang&#39;...\nSubmodule path &#39;3rdparty/tvm/3rdparty/rang&#39;: checked out &#39;cabe04d6d6b05356fa8f9741704924788f0dd762&#39;\n+ cd /usr/local/mxnet\n+ git checkout eaa6253\nwarning: unable to rmdir 3rdparty/dlpack: Directory not empty\nwarning: unable to rmdir 3rdparty/dmlc-core: Directory not empty\nwarning: unable to rmdir 3rdparty/googletest: Directory not empty\nwarning: unable to rmdir 3rdparty/mkldnn: Directory not empty\nwarning: unable to rmdir 3rdparty/nvidia_cub: Directory not empty\nwarning: unable to rmdir 3rdparty/onnx-tensorrt: Directory not empty\nwarning: unable to rmdir 3rdparty/openmp: Directory not empty\nwarning: unable to rmdir 3rdparty/ps-lite: Directory not empty\nwarning: unable to rmdir 3rdparty/tvm: Directory not empty\nNote: checking out &#39;eaa6253&#39;.\n\nYou are in &#39;detached HEAD&#39; state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by performing another checkout.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -b with the checkout command again. Example:\n\n  git checkout -b &lt;new-branch-name&gt;\n\nHEAD is now at eaa6253... Adding quick installation script for installing MXNet with Python on Amazon Linux (#3927)\n+ git submodule update\n+ echo &#39;**** Building MXNet ****&#39;\n**** Building MXNet ****\n++ nproc\n+ USE_CUDA=0\n+ USE_CUDNN=0\n+ USE_CUDA_PATH=/usr/local/cuda\n+ USE_BLAS=openblas\n+ make -e -j8\nMakefile:23: mshadow/make/mshadow.mk: No such file or directory\nMakefile:24: /usr/local/mxnet/dmlc-core/make/dmlc.mk: No such file or directory\nMakefile:113: /usr/local/mxnet/ps-lite/make/ps.mk: No such file or directory\nmake: *** No rule to make target &#39;/usr/local/mxnet/ps-lite/make/ps.mk&#39;.  Stop.\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["%sh\npip install mxnet"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting mxnet\n  Downloading https://files.pythonhosted.org/packages/92/6c/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4MB)\nCollecting graphviz&lt;0.9.0,&gt;=0.8.1 (from mxnet)\n  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\nRequirement already satisfied: requests&lt;3,&gt;=2.20.0 in /databricks/python3/lib/python3.7/site-packages (from mxnet) (2.21.0)\nRequirement already satisfied: numpy&lt;2.0.0,&gt;1.16.0 in /databricks/python3/lib/python3.7/site-packages (from mxnet) (1.16.2)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet) (2019.3.9)\nRequirement already satisfied: urllib3&lt;1.25,&gt;=1.21.1 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet) (1.24.1)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet) (2.8)\nInstalling collected packages: graphviz, mxnet\nSuccessfully installed graphviz-0.8.4 mxnet-1.5.1.post0\nYou are using pip version 19.0.3, however version 19.3.1 is available.\nYou should consider upgrading via the &#39;pip install --upgrade pip&#39; command.\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["With python, it is normally only necessary to install a module before you can start using it.  However, when working in a notebook, python is already “running”.  So, python will not notice that the MXNet module is available unless you “restart” python.  \n\nThis is simpler than it sounds.  Simply use the cluster menu to `Detach` from your cluster.  Then use the menu again to `Attach` to the cluster.  The notebook will be executed again with a fresh instance of python, and you should be able to import MXNet as you normally would.\n\nTry importing `mxnet` now as `mx`, and `print` `__version__`."],"metadata":{}},{"cell_type":"code","source":["import mxnet as mx\nprint (mx.__version__)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1.5.1\n</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["With module installation out of the way.  Lets get started by loading some data."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport os\nimport urllib.request\nimport gzip\nimport struct\n\ndef download_data(url, force_download=True): \n    fname = url.split(\"/\")[-1]\n    if force_download or not os.path.exists(fname):\n        urllib.request.urlretrieve(url, fname)\n    return fname\n\ndef read_data(label_url, image_url):\n    with gzip.open(download_data(label_url)) as flbl:\n        magic, num = struct.unpack(\">II\", flbl.read(8))\n        label = np.fromstring(flbl.read(), dtype=np.int8)\n    with gzip.open(download_data(image_url), 'rb') as fimg:\n        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n    return (label, image)\n\npath='http://yann.lecun.com/exdb/mnist/'\n(train_lbl, train_img) = read_data(\n    path+'train-labels-idx1-ubyte.gz', path+'train-images-idx3-ubyte.gz')\n(val_lbl, val_img) = read_data(\n    path+'t10k-labels-idx1-ubyte.gz', path+'t10k-images-idx3-ubyte.gz')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1578135275698-0/PythonShell.py:16: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n  from collections import OrderedDict\n/local_disk0/tmp/1578135275698-0/PythonShell.py:19: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n  from tempfile import NamedTemporaryFile\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nfor i in range(10):\n    plt.subplot(1,10,i+1)\n    plt.imshow(train_img[i], cmap='Greys_r')\n    plt.axis('off')\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["print('label: %s' % (train_lbl[0:10],))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["Create data iterators"],"metadata":{}},{"cell_type":"code","source":["def to4d(img):\n    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n\nbatch_size = 100\ntrain_iter = mx.io.NDArrayIter(to4d(train_img), train_lbl, batch_size, shuffle=True)\nval_iter = mx.io.NDArrayIter(to4d(val_img), val_lbl, batch_size)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Multilayer Perceptron"],"metadata":{}},{"cell_type":"code","source":["# Create a place holder variable for the input data\ndata = mx.sym.Variable('data')\n# Flatten the data from 4-D shape (batch_size, num_channel, width, height) \n# into 2-D (batch_size, num_channel*width*height)\ndata = mx.sym.Flatten(data=data)\n\n# The first fully-connected layer\nfc1  = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)\n# Apply relu to the output of the first fully-connnected layer\nact1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n\n# The second fully-connected layer and the according activation function\nfc2  = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden = 64)\nact2 = mx.sym.Activation(data=fc2, name='relu2', act_type=\"relu\")\n\n# The thrid fully-connected layer, note that the hidden size should be 10, which is the number of unique digits\nfc3  = mx.sym.FullyConnected(data=act2, name='fc3', num_hidden=10)\n# The softmax and loss layer\nmlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Now both the network definition and data iterators are ready. We can start training."],"metadata":{}},{"cell_type":"code","source":["model = mx.model.FeedForward(\n    symbol = mlp,       # network structure\n    num_epoch = 10,     # number of data passes for training \n    learning_rate = 0.1 # learning rate of SGD \n)\nmodel.fit(\n    X=train_iter,       # training data\n    eval_data=val_iter, # validation data\n    batch_end_callback = mx.callback.Speedometer(batch_size, 200) # output progress for each 200 data batches\n) "],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["After training is done, we can predict a single image."],"metadata":{}},{"cell_type":"code","source":["plt.clf()\nplt.imshow(val_img[0], cmap='Greys_r')\nplt.axis('off')\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["prob = model.predict(val_img[0:1].astype(np.float32)/255)[0]\nprint 'Classified as %d with probability %f' % (prob.argmax(), max(prob))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["We can also evaluate the accuracy by given a data iterator."],"metadata":{}},{"cell_type":"code","source":["print 'Validation accuracy: %f%%' % (model.score(val_iter)*100,)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Convolutional Neural Networks"],"metadata":{}},{"cell_type":"code","source":["data = mx.symbol.Variable('data')\n# first conv layer\nconv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\ntanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\npool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n# second conv layer\nconv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\ntanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\npool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n# first fullc layer\nflatten = mx.sym.Flatten(data=pool2)\nfc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\ntanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n# second fullc\nfc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n# softmax loss\nlenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["Note that LeNet is more complex than the previous multilayer perceptron, so we use GPU instead of CPU for training.  \nNOTE: This takes up to 45 minute on the community edition - this is the point at which you could integrate with Spark (i.e. via broadcast, etc...)  to optimize."],"metadata":{}},{"cell_type":"code","source":["model = mx.model.FeedForward(\n#     ctx = mx.gpu(0),     # use GPU 0 for training, others are same as before\n    symbol = lenet,       \n    num_epoch = 10,     \n    learning_rate = 0.1)\nmodel.fit(\n    X=train_iter,  \n    eval_data=val_iter, \n    batch_end_callback = mx.callback.Speedometer(batch_size, 200)\n) "],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["print 'Validation accuracy: %f%%' % (model.score(val_iter)*100,)"],"metadata":{},"outputs":[],"execution_count":25}],"metadata":{"name":"9-Use-MxNET","notebookId":200060826016244},"nbformat":4,"nbformat_minor":0}
